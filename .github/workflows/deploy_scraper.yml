# .github/workflows/deploy_scraper.yml
name: CI/CD â€” Test, Build & Deploy Scraper Lambda Image

on:
  push:
    branches: [ main ]
    paths:
      - 'main_scraper/**'
      - 'scrapers/**'
      - 'tests/**'
      - '.github/workflows/deploy_scraper.yml'

jobs:
  test-build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      # 1. Checkout your repository
      - name: Checkout code
        uses: actions/checkout@v3

      # 2. Set up Python for testing
      - name: Set up Python 3.13
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'

      # 3. Install your runtime dependencies + pytest
      - name: Install dependencies for tests
        run: |
          python -m pip install --upgrade pip
          pip install -r main_scraper/requirements.txt
          pip install pytest

      # 4. Run the scraper tests
      - name: Run tests with pytest
        run: pytest --maxfail=1 --disable-warnings -q

      # 5. Configure AWS credentials for S3, ECR & Lambda
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            eu-central-1

      # 6. Fetch headless-chromium and chromedriver from S3 into build context
      - name: Download headless-chromium from S3
        run: |
          mkdir -p main_scraper/bin
          aws s3 cp \
            s3://stagehop-lambda-dependencies/bin/headless-chromium \
            main_scraper/bin/headless-chromium --region eu-central-1
          chmod +x main_scraper/bin/headless-chromium

      - name: Download chromedriver from S3
        run: |
          aws s3 cp \
            s3://stagehop-lambda-dependencies/bin/chromedriver \
            main_scraper/bin/chromedriver --region eu-central-1
          chmod +x main_scraper/bin/chromedriver

      # 7. Log in to your ECR registry
      - name: Login to Amazon ECR
        run: |
          aws ecr get-login-password --region eu-central-1 \
            | docker login --username AWS --password-stdin 251995574407.dkr.ecr.eu-central-1.amazonaws.com

      # 8. Build, tag, and push the Docker image
      - name: Build & push Docker image
        run: |
          IMAGE_URI=251995574407.dkr.ecr.eu-central-1.amazonaws.com/scraper-lambda-repo:latest
          docker build -t scraper-lambda -f main_scraper/dockerfile .
          docker tag scraper-lambda:latest $IMAGE_URI
          docker push $IMAGE_URI

      # 9. Update Lambda to use the new image
      - name: Deploy to Lambda
        run: |
          aws lambda update-function-code \
            --function-name scraper-lambda \
            --region eu-central-1 \
            --image-uri 251995574407.dkr.ecr.eu-central-1.amazonaws.com/scraper-lambda-repo:latest \
            --publish
